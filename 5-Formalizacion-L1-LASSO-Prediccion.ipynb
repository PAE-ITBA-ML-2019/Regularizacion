{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/PAE-ITBA-ML-2019/Regularizacion/master/reg_helper.py\n",
    "! wget https://raw.githubusercontent.com/PAE-ITBA-ML-2019/Regularizacion/master/fnn_helper.py\n",
    "! wget https://raw.githubusercontent.com/PAE-ITBA-ML-2019/Regularizacion/master/draw_nn.py\n",
    "! wget https://raw.githubusercontent.com/PAE-ITBA-ML-2019/Regularizacion/master/regularization_helper.py\n",
    " \n",
    "! wget https://github.com/PAE-ITBA-ML-2019/Regularizacion/raw/master/data.zip\n",
    "! unzip data.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO \n",
    "**(Least Absolute Shrinkage and Selection Operator) -L1 regularization-**\n",
    "- L2 primero reduce los pesos con magnitudes altas por que para mismo delta de reducción, si la magnitud es alta, la reducción es mayor. L1 en cambio por ser lineal da igual si la magnitud es alta o baja.\n",
    "- L2 no da \"sparsity\" va bajando todos al mismo tiempo.\n",
    "- Selector de parametros (Feature selection) - Puede tratar los pesos en forma independiente. Cuando un peso es cero, No importa la relación con el resto como en L2. Sí depende de la función de costo\n",
    "- $g(w) = \\|w\\|$ \n",
    "- Sparse solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lasso.png\" alt=\"Drawing\" style=\"width:60%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO vs RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from reg_helper import get_lin_reg_pol, get_ridge_weights, get_MLE_MAP_weights, plt_lin_reg_gauss, get_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/alturas-pesos-mils-train.csv')\n",
    "data = df[['Altura', 'Peso']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[:,0], data[:,1], s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo con polinomio de orden 7 tomando de a 20 observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 # Cantidad de observaciones\n",
    "i_sel = 3 # Tomadas de a N cual de las 8000/N tomo\n",
    "order = 7 # Orden del polinomio\n",
    "ptos=100 # Resolución de recta\n",
    "al = np.linspace(data[:,0].min(),data[:,0].max(), ptos)\n",
    "alturas_pol, mean, std = get_lin_reg_pol(data[:,0], order, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha es lambda (Notación Sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-3, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_MSE = get_ridge_weights(alturas_pol[i_sel*N:(i_sel+1)*N, :], data[:,1][i_sel*N:(i_sel+1)*N], lamb = 0).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_MSE.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_RIDGE = np.zeros([len(alphas), order+1])\n",
    "ws_LASSO = np.zeros([len(alphas), order+1])\n",
    "for i, alpha in enumerate(alphas):\n",
    "    clf_ridge = Ridge(alpha = alpha, fit_intercept=False)\n",
    "    clf_ridge.fit(alturas_pol[i_sel*N:(i_sel+1)*N, :], data[:,1][i_sel*N:(i_sel+1)*N])\n",
    "    w_RIDGE = np.array(list(clf_ridge.coef_))\n",
    "    w_RIDGE = get_ridge_weights(alturas_pol[i_sel*N:(i_sel+1)*N, :], data[:,1][i_sel*N:(i_sel+1)*N], lamb = alpha).reshape(1,-1)\n",
    "    clf_lasso = Lasso(alpha = alpha, fit_intercept=False, tol=0.0001, max_iter=100000)\n",
    "    clf_lasso.fit(alturas_pol[i_sel*N:(i_sel+1)*N, :], data[:,1][i_sel*N:(i_sel+1)*N])\n",
    "    w_LASSO = np.array(list(clf_lasso.coef_))\n",
    "    ws_RIDGE[i,:] = w_RIDGE\n",
    "    ws_LASSO[i,:] = w_LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aclaración: No estoy graficando el intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.semilogx(alphas, ws_RIDGE[:,1:])\n",
    "plt.title(\"Valor de los $w_i$'s en función de $\\lambda$ -Ridge-\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.semilogx(alphas[20:], ws_RIDGE[20:,1:])\n",
    "plt.title(\"Valor de los $w_i$'s en función de $\\lambda$ -Ridge- Zoom\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.semilogx(alphas, ws_LASSO[:,1:])\n",
    "plt.title(\"Valor de los $w_i$'s en función de $\\lambda$ -LASSO- \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar en la gráfica superior como algunos pesos se van a cero (Sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()\n",
    "clf.fit(data[:,0][i_sel*N:(i_sel+1)*N].reshape(-1,1), data[:,1][i_sel*N:(i_sel+1)*N])\n",
    "w_LR = np.array([clf.intercept_, clf.coef_[0]]).reshape(2,1)\n",
    "print(w_LR)\n",
    "pe_LR = get_lin_reg_pol(al, normalize=False, order=1).dot(w_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión de ridge en función de lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "al = np.linspace(data[:,0][i_sel*N:(i_sel+1)*N].min(),data[:,0][i_sel*N:(i_sel+1)*N].max(), ptos)\n",
    "al_line = get_lin_reg_pol(al, normalize=False, order=order, mean=mean, std=std)\n",
    "paso = 8\n",
    "plt.plot(al, pe_LR, 'k', label='regresión lineal')\n",
    "plt.plot(al, al_line.dot(w_MSE.T), 'k', ls='-.',label='$\\lambda$=0')\n",
    "for i, w in enumerate(ws_RIDGE[::paso]):\n",
    "    pe_RIDGE = al_line.dot(w)\n",
    "    plt.plot(al, pe_RIDGE, label='$\\lambda$='+str(np.round(alphas[i*5]*1000)/1000))\n",
    "\n",
    "plt.legend()\n",
    "plt.scatter(data[:,0][i_sel*N:(i_sel+1)*N], data[:,1][i_sel*N:(i_sel+1)*N])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve claramente el aumento de bias con el aumento de lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión L1 en función de lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "al_line = get_lin_reg_pol(al, normalize=False, order=order, mean=mean, std=std)\n",
    "paso = 8\n",
    "plt.plot(al, pe_LR, 'k', label='regresión lineal')\n",
    "plt.plot(al, al_line.dot(w_MSE.T), 'k', ls='-.',label='$\\lambda$=0')\n",
    "for i, w in enumerate(ws_LASSO[::paso]):\n",
    "    pe_LASSO = al_line.dot(w)\n",
    "    plt.plot(al, pe_LASSO, label='$\\lambda$='+str(np.round(alphas[i*5]*1000)/1000))\n",
    "\n",
    "plt.legend()\n",
    "plt.scatter(data[:,0][i_sel*N:(i_sel+1)*N], data[:,1][i_sel*N:(i_sel+1)*N])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet\n",
    "-  Combinacion de L1 y L2\n",
    "\n",
    "# 4.4 Sparcity y LO regularization:\n",
    "\n",
    "$w_{RR} = arg \\min\\| \\hat{y}-y_i \\|^2 + \\lambda \\|w\\|^d$\n",
    "\n",
    "- L0 cuenta la cantidad de $w$'s distinto de cero (d=0)\n",
    "- Si d esta entre 0 y 1 aumenta la esparcibidad (sparsity) pero la funcion de costo no es convexa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
